It's not entirely clear to me what is expected of me in this project. The [instructions](./scrapy-mini-project.rst) just contain a follow-along exercise for a single web scraper, and then specified to submit "data scraped using the 2 different kind of spiders (toscrape-css.py and toscrape-xpath.py)".

It does briefly mention xpath expressions, so I'm assuming the idea is to write a separate scraper class replacing css selectors with xpath expressions. That's what I've done here in the [spiders](./scrapy_mini_project/scrapy_mini_project/spiders/) subdirectory. Because there isn't much detail on xpath expressions in this document, I'm just using the expressions generated by scrapy using css selectors. This is presumably not the simplest way to go about that task, but it gets the job done.

Output from the two spiders are included in [quotes-css.json](./scrapy_mini_project/quotes-css.json) and [quotes-xpath.json](./scrapy_mini_project/quotes-xpath.json) respectively. It can be reproduced as follows:

```bash
cd scrapy_mini_project
scrapy crawl quotes-css -o quotes-css.json
scrapy crawl quotes-xpath -o quotes-xpath.json
```